# 3. Deployment

Now that Terraform has provisioned the Azure infrastructure that we need for our serverless solution, we need to take the final step of deploying both the deployment artifacts to the appropriate locations in Azure.

![Resource][image-1]

_The .NET CLI produces deployment artifacts that are provisioned to Azure after Terraform executes_

We will use .NET and Azure custom tools to produce the artifacts and deploy them to these target locations.

## Frontend

As we saw in other chapters, our .NET application code needs to follow a Continuous Integration process where the code is built and tested using automated unit testing and other built-in quality controls. Nothing changes there, except that we need to add some special handling to the deployment artifact that these processes produce in order to make sure it is available to our GitHub Action's job that deploys the workload to the appropriate location.

The `dotnet publish` command is used to output the deployment artifact of the .NET application code. For the ASP.NET Blazor web application, this output is a folder container, a collection of loose files with HTML, JavaScript, and CSS in it. In order to pass all these files efficiently from one GitHub Actions Job to another, we need to zip them up into a single file.

	    - name: Generate the Deployment Package
	      run: |
	        zip -r ../deployment.zip ./
	      working-directory: ${{ env.DOTNET_WORKING_DIRECTORY }}/publish

Now that the static web content is zipped into a zip archive, we use the `upload-artifact` GitHub Action to save this file to GitHub Actions. This will make the file available for future jobs that are executed within the pipeline.

	    - name: Upload Deployment Package
	      uses: actions/upload-artifact@v2
	      with:
	        name: dotnet-deployment
	        path: ${{ env.DOTNET_WORKING_DIRECTORY }}/deployment.zip

Future jobs can simply download the artifact using a corresponding `download-artifact` GitHub Action and the same name that was used to upload it.

	    - uses: actions/download-artifact@v3
	      with:
	        name: dotnet-deployment

Because the ASP.NET Blazor web application is going to be hosted as static web content on our Azure Storage Account we need to ensure that we unzip it in order to upload the contents to Azure Blob Storage. If we were to upload the zip archive to Blob Storage, the web application wouldn't work correctly because all of the web content would be trapped inside the archive file.

	    - name: Unzip Deployment Package
	      run: |
	        mkdir -p ${{ env.DOTNET_WORKING_DIRECTORY }}/upload-staging
	        unzip ./deployment.zip -d ${{ env.DOTNET_WORKING_DIRECTORY }}/upload-staging

Now that the static web content is unzipped to the staging directory, we can use the `az storage blob upload-batch` command to deploy all of the files to the `$web` container.

	    - id: deploy
	      name: Upload to Blob
	      env:
	        ARM_SUBSCRIPTION_ID: ${{ vars.ARM_SUBSCRIPTION_ID }}
	        ARM_TENANT_ID: ${{ vars.ARM_TENANT_ID }}
	        ARM_CLIENT_ID: ${{ vars.TERRAFORM_ARM_CLIENT_ID }}
	        ARM_CLIENT_SECRET: ${{ secrets.TERRAFORM_ARM_CLIENT_SECRET }}
	      working-directory: ${{ env.DOTNET_WORKING_DIRECTORY }}
	      run: |
	        az login --service-principal -u $ARM_CLIENT_ID -p $ARM_CLIENT_SECRET --tenant $ARM_TENANT_ID
	        az account set --subscription $ARM_SUBSCRIPTION_ID
	        az storage blob upload-batch -s ./upload-staging/wwwroot -d \$web --account-name ${{ steps.terraform.outputs.frontend_storage_account_name }}

We need to make sure that we authenticate with Azure and that we are targeting the right Azure Subscription that has our Azure Storage Account that we want to target. Therefore, we need to execute the `az login` command to authenticate and then `az account set` to ensure we are working on the right Subscription. Once that is done, we can execute `az storage blob upload-batch` in order to recursively upload all the files within the staging directory.


## Azure Function

In order to deploy the Azure Function, the exact same process is followed to pass the artifact from the GitHub Actions job that builds the deployment artifact to the job that actually deploys the artifact. 

Like the `az storage blob upload-batch` command, we also need to authenticate and set the right Azure Subscription. The only difference is that we are using the `az functionapp deployment source config-zip` command to provision a zip archive to the Azure Function.

	      - name: Deploy
	        env:
	          ARM_SUBSCRIPTION_ID: ${{ vars.ARM_SUBSCRIPTION_ID }}
	          ARM_TENANT_ID: ${{ vars.ARM_TENANT_ID }}
	          ARM_CLIENT_ID: ${{ vars.TERRAFORM_ARM_CLIENT_ID }}
	          ARM_CLIENT_SECRET: ${{ secrets.TERRAFORM_ARM_CLIENT_SECRET }}
	          RESOURCE_GROUP_NAME: ${{needs.terraform.outputs.resource_group_name}}
	          FUNCTION_NAME: ${{needs.terraform.outputs.function_name}}
	        run: |
	          az login --service-principal -u $ARM_CLIENT_ID -p $ARM_CLIENT_SECRET --tenant $ARM_TENANT_ID --output none
	          az account set -s $ARM_SUBSCRIPTION_ID --output none
	          az functionapp deployment source config-zip -g $RESOURCE_GROUP_NAME -n $FUNCTION_NAME --src ./deployment.zip

Unlike how we provisiioned the Frontend, we don't need to unzip the deployment package for the Azure Function. Azure Functions is expecting our application code to be bundled into a zip archive.

	  app_settings = {
	    "SCM_DO_BUILD_DURING_DEPLOYMENT" = "false"
	    "WEBSITE_RUN_FROM_PACKAGE"       = "1"
	  }

You might remember from the previous section where we set the `app_settings` on the Azure Function, we set two settings `SCM_DO_BUILD_DURING_DEPLOYMENT` and `WEBSITE_RUN_FROM_PACKAGE`. These two settings are telling Azure Functions that our application code is already pre-compiled and bundled into a zip archive.

That's it! Now, our application has been fully deployed to Azure Storage and Azure Functions! 

[image-1]:	../images/Serverless-DeploymentPackage.png