# 3. Stand-Alone Application

For most of this book we have been operating as a small team at the illusive billionaire magnate, Keyser Söze's firm building a next generation Fleet Operations platform. In these scenarios we worked across multiple clouds and implemented our solution using three different cloud computing paradigms along the way.

![Small Team][image-1]
_Operating Model for a small team deploying a stand-alone application_

In this scenario we saw an application development team that was working on a typical N-tier architecture application. The team was probably 6-8 people that consistented ofsoftware developers and software testers. The ultimate goal is not to provision infrastructure but to facilitate a release process for the application software the team is developing.

In these types of teams it’s not uncommon for both the application code and the infrastructure-as-code to be maintained within the same source code repository. This simple approach recognizes the natural dependencies between the infrastructure and the application as a result of the deployment process. The presence of well-known secrets is provisioned by the infrastructure-as-code but referenced by the application during its initialization. Keeping it all in our source code repository allows us to minimize the mechanics of making changes that cascade across the infrastructure and application codebase in a single feature branch, pull request, and ultimately merge into `main.`

We have a single Terraform root module that we use to deploy our environments and we alter the input variables to configure it appropriately for different instances of the environment: “DEV” and “PROD”. This allows us to manage a multitude of environments simply by changing which workspace we point at either using the `terraform workspace` command or by changing the Backend Key that we use to partition the workspace within the backend.

The solution that we built and deployed was an end-to-end solution with multiple architectural components that made up the entire application. In this case an application with a web front end and a REST API as its backend—not an uncommon scenario. Because our solution was so simple we were able to operate in a completely self-contained manner. This isn’t always the case as we’ll see later in larger teams and larger environments—particularly in the enterprise.

During the solution development that we did in Chapters 7 through 15, we didn’t really address how those environments would be managed in production. In a normal product development process, we would need to provision multiple environments for various purposes and manage our release lifecycle across these environments until we finally shipped the product by deploying it into production.

As we saw along this journey, in addition to the subtle and sometimes not-so-subtle differences between cloud platforms, depending on the cloud computing paradigm, we would use different mediums for packaging our application deployment, which sometimes allowed us to integrate the deployment artifact into our Terraform configuration by referencing the Virtual Machine Image or the Container Image but sometimes, as with serverless, we had to implement an additional stand-alone deployment procedure that would execute after Terraform provisioned our environments. 

[image-1]:	../images/Ops-SmallTeams1.png