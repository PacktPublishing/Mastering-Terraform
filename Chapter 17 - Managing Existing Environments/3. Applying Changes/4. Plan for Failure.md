# 4. Plan for Failure

Sometimes the unexpected happens and part of our infrastructure is impacted due to an outage of some kind on the target cloud platform. In these situations we need to be able to react and bring change to our existing environments in order to minimize the damage or recover from the outage.

## Active-Passive

![Active-Passive Deployment][image-1]
Active-Passive Workload deployed within a single Terraform Workspace

![Outage][image-2]
Active-Passive Workload when disaster strikes!

the application and database in US West are unavailable. Luckily we have the database in US East that we were replicating to. However, we need to create an online environment to start serving our customers using this database.

![Create New Environment][image-3]
Provision a new deployment in a new Terraform Workspace

We use Terraform to provision a new environment in a new Terraform workspace. We configure the new root module to use the US East as the primary region and the secondary region as another healthy region nearby, in this case, US Central. This environment is healthy, but itâ€™s missing our data.

![Reference Old Database][image-4]
We reconfigure your new workspace to reference the "old" database by importing it into the state, essentially replacing the new empty database with the old database. This will also likely cause a replacement of the replication configuration to start replication from the old database to the new Disaster Recovery database in the US Central region.

![Replace with Old Database][image-5]

Now, the old Disaster Recovery database in US East is our main production database, and we have a new Disaster Recovery site in US Central in case we need to perform this same operation again. At this point, we are ready to resume service with our customers by allowing traffic back to our application. The database will be up-to-date because of the previous replication that was in place from the US West to the US East. There might be minor data loss for some customers during the small window when the requests were recorded in the U.S. West but may not have made it over to the U.S. East through the replication.

## Active-Active


![Active-Active No Modules][image-6]
Active-Active deployment in a single Terraform Workspace without using any modules

To achieve higher levels of system availability we can opt for an Active-Active cross region deployment. In this situation, we will have two instances of our application deployed across two regions and replication between the databases. This will ensure that in case of an outage in one region our customers will continue to be served by routing traffic to the healthy region.

In the above approach, we created our multi-region deployment in a single Terraform Workspace, which means both regions will be updated on a single Terraform application. This can be problematic because if one region is down, then half of our deployment will be potentially unresponsive, thus impacting our ability to enact change across the entire environment. This could impact our ability to failover, increase capacity, or adjust auto-scale settings in the unaffected region.

In order to start moving away from deploying all of our regions into a single Terraform Workspace, it is a good idea to encapsulate an entire regional deployment into a single reusable module. In doing so, we make it much easier to segment our Terraform Workspaces across regions and easily add additional regions as we scale out.

![Active-Active Module Design][image-7]
Module Design to encapsulate our Application deployment within a single Region

The module will have everything that needs to be deployed into a single region. In addition, there may be optional components, such as the database replication configuration, that may not need to be enabled depending on whether this region is the primary or one of the secondary endpoints. Therefore, our module needs to take two input variables. First, the region that this instance of our application will be deployed into. Then, there is a feature flag to enable or disable database replication. This will be enabled when the region is our primary, but it will be disabled when it is set up as a secondary.

This is an example, your mileage may vary depending on the database or technologies that you are using but its important to recognize that it is a common scenario in such modules to leverage feature flags to allow the customization of each instance of the module to fulfill its specific role.

![Active-Active with Modules][image-8]
Active-Active deployment in a single Terraform Workspace using modules to provision each region

Now that we have our module we can use it within our single Terraform workspace to provision both regions. This approach allows for additional regions to be provisioned quite easily within a single Terraform Apply, but it is susceptible to operational impact when an outage occurs. If you have designed your failover mechanism and secondary regions to be self-sufficient, then this approach may not be unreasonable, but just remember that you may lose the ability to perform Terraform Apply operations during the outage.

Even when performing a Targeted Apply, it will execute a plan across the entire workspace. So even though, in theory, a targeted `terraform apply` will only change resources that you target because it has to perform a full plan, if the control plane you are targeting is impacted in certain regions or zones, then you will be unable to do so.

![Active-Active with Separate Workspaces][image-9]

Transitioning to completely separate workspaces for each region can help you maintain control over your environments through Terraform because you will be performing a `terraform apply` within the context of each region. This adds additional operational overhead during steady state as it creates additional Terraform Workspaces to manage and additional mechanics when performing day-to-day maintenance of your environment so many might still opt for a single workspace to manage multi-region environments.

[image-1]:	../images/Failure1-Active-Passive.png
[image-2]:	../images/Failure1-Active-Passive-Step1-Outage.png
[image-3]:	../images/Failure1-Active-Passive-Step2-NewEnvironment.png
[image-4]:	../images/Failure1-Active-Passive-Step3-ReferenceOldDB.png
[image-5]:	../images/Failure1-Active-Passive-Step4-ReplaceWithOld.png
[image-6]:	../images/Failure2-Active-Active-NoModules.png
[image-7]:	../images/Failure2-Active-Active-ModuleDesign.png
[image-8]:	../images/Failure2-Active-Active-WithModules.png
[image-9]:	../images/Failure2-Active-Active-WithSeparateWorkspaces.png