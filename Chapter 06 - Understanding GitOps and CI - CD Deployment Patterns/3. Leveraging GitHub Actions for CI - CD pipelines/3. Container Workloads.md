# 3. Container Workloads

When building automation pipelines that provision Container-based workloads, your toolchain should consist of something that can be used to set the initial configuration of the various containers that need to be deployed, provision the Kubernetes cluster to host the containers and the underlying infrastructure that supports the Kubernetes cluster’s operations and then finally provisioning Kubernetes resources to the Kubernetes control plane using Kubernetes own REST API through a variety of different options.

Due to the immutability of the container images and their lightweight and speedy nature, it’s easy to implement sophisticated rolling updates to roll out new versions of the container image across existing deployments. Therefore, the mechanics around provisioning and maintaining container-based workloads are really about building new container images and referencing the desired image within your Kubernetes configuration to invoke an update to the deployment.

## Docker Build Pipeline

As we discussed when we looked at the principles around Docker and how it works, developers write and commit Docker files using to their Git repository.

An independent pipeline is triggered when changes are pushed to the version control system affecting the folder where the Docker configuration files are stored. Within that pipeline, Docker is utilized to build container images for each server role (e.g., frontend, backend, and database) within the application. Docker is configured with the latest configurations for each role within the application, including the necessary software and settings unique to each layer. The Docker image that is produced acts as our deployment package. As a result, it is versioned and stored in a Package Repository called a Container Registry (which we discussed in Chapter 5). Once the new Docker image is there, we can reference it from the Kubernetes configuration and trigger a deployment in Kubernetes in a myriad of ways.

## Kubernetes Manifest Update Pipeline

In this pipeline, when developers modify the manifests to reference the new version of the Docker image that was built and published in the previous step and submit a pull request to update the change. The trigger we use can be either a Push Model or a Pull Model. If you recall, in Chapter 5 on Container-based Architectures, we discussed several different methods for implementing a Push Model in this manner. Some options use `kubectl` and Kubernetes YAML manifests, and others use a Helm Chart with a set of YAML manifests that have been turned into a more dynamic template by using Helm. 

Alternatively, using the Pull Model, we could use a Continuous Deployment agent hosted on the Kubernetes cluster itself, like ArgoCD, that would pick up on changes within the Git repository and apply them to the cluster. Because ArgoCD is continuously monitoring the Git repository containing the Kubernetes manifests (or Helm Charts), whenever a new commit is made to the repository, it will automatically trigger a deployment process. ArgoCD isn’t doing any magic; it is simply using `kubectl apply` to apply the latest version of the manifests to the Kubernetes cluster.

## Terraform Apply Pipeline

As we have discussed in Chapter 5, due to Kubernetes architecture, the Kubernetes cluster is often a shared resource where multiple teams will deploy their own workloads by targeting their own namespace within the cluster. That’s why it’s often the case that this pipeline may be managed by a different team than the ones that own the Docker Build and Kubernetes Manifest pipelines. This pipeline is owned by the team responsible for provisioning and maintaining the Kubernetes cluster. Their responsibility is to ensure that the cluster is up and running and ready to accept deployments from ArgoCD.

Terraform could optionally be used to manage Kubernetes resources on the cluster, but as we addressed in Chapter 5, this may not be ideal in all situations due to team and organizational dynamics. It’s best to consider your specific context and make the right decision for your team and organization.

In most cases, Terraform is simply used to provision the Kubernetes cluster and surrounding infrastructure on the cloud platform of choice. Developers will commit Terraform configuration files to their Git repository, and the pipeline is triggered whenever changes are pushed to the folder where the Terraform configuration is stored.

This approach allows developers to focus on code development and testing without worrying about the underlying infrastructure and deployment process. The development teams can rely on an isolated environment within the Kubernetes cluster that they deploy to and really only need to maintain their codebase and the Docker file used to configure their application.
