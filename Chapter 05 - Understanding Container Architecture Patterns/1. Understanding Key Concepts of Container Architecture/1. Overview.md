# 1. Overview

Virtual Machines are great when you want minimal changes to operate your applications and software in the cloud, but they also have drawbacks. With the maximum control you get from having a full Virtual Machine—of whatever size you happened to provision—you are free to use as much (or as little) of the Virtual Machine's resources as you can. However, many organizations have found that their fleet of Virtual Machines is plagued by low utilization even when best practices in workload isolation or the "single responsibility principle" are followed. 

Inversely, when maximum utilization is the objective, organizations load up a single Virtual Machine with so many disparate services and components that each Virtual Machine—while highly utilized—becomes a bit of a quagmire to manage and maintain. The Virtual Machine will have a myriad of dependency conflicts, with resource contention cropping up between the horde of independent but cohabitating processes within the same Virtual Machine.

This dilemma between workload isolation and resource utilization is the problem that container technology aims to solve and where container orchestrators, like Kubernetes, help by bringing resiliency and scalability. 

In this book, we will build an end-to-end solution using Kubernetes-based container technology on AWS, Azure, and Google Cloud Platform. To do so, you must understand some critical concepts that transcend cloud platforms to help you navigate the architecture and relevant Terraform resources within the respective cloud platform's Terraform provider.
