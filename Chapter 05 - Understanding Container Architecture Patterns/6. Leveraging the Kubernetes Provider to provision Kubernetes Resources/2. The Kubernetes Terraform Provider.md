# 2. The Kubernetes Terraform Provider

As we discussed in the previous section, because Kubernetes has a REST API that acts as a uniform control plane for all management operations its possible to create a Terraform provider that we can use to automate it in the same fashion that we do with the cloud platforms AWS, Azure and Google Cloud.

Just like other cloud platforms, we need to authenticate against the control plane. One big difference with Kubernetes is that the management control plane is hosted on the Kubernetes cluster itself, more specifically, as we discussed in Section 4 of this chapter, on the Master Node. This means we need to specify the endpoint address of the Kubernetes cluster. This is usually provided by the Terraform resource that provisions the Kubernetes cluster on the target cloud platform.

In order to authenticate with the Kubernetes cluster, we need typically use a cluster certificate, but some cloud platforms support more sophisticated authentication methods that tie into your organization’s directory systems like Microsoft Entra ID.

Here is an example of what the provider configuration would typically look like when using certificate-based authentication:

	provider "kubernetes" {
	  host                   = var.cluster_endpoint
	
	  client_certificate     = file(var.client_cert_path)
	  client_key             = file(var.client_key_path)
	  cluster_ca_certificate = file(var.cluster_ca_cert_path)
	}

Here's what each field is for:

- `host`: The hostname (in the form of URI) of Kubernetes master. It can be sourced from the `KUBE_HOST` environment variable.
- `client_certificate `: This is used for client authentication against the Kubernetes REST API.
- `client_key `: This is paired with the `client_certificate` and is used as part of the TLS handshake that happens between the Terraform provider and the Kubernetes REST API.
- `cluster_ca_certificate`: This is the certificate authority for the Kubernetes cluster and is used to verify the authenticity of the Kubernetes cluster’s REST API.

Another common method for configuring the Kubernetes provider for Terraform is to use a `kube_config` file. 

	provider "kubernetes" {
	  load_config_file = true
	  config_path      = "~/.kube/config"
	  context          = "foo"
	}

In this situation, all of the details needed to connect and authenticate with the cluster are stored within the file. We just need to point the provider at the location where the file exists. By default, this location is `~/.kube/config`. Of course, this file can contain multiple cluster connections, each referred to as a ‘context’. Therefore, we may need to specify the context. However, if you are running in a CI / CD pipeline, this is very unlikely because you will likely use a custom path.