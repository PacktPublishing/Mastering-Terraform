# 3. The Helm Terraform Provider

In the last section, we looked at how Helm works, the structure of a Helm chart, and how its structure and functionality compare and contrast to Terraform Modules. Now, we’ll look at how we can use Terraform to manage our Kubernetes environment using the Helm provider for Terraform. This provider is a close brother to the Kubernetes provider for Terraform because they both interact with the Kubernetes REST API as the control plan for managing Terraform resources.

The advantage of using Terraform with Helm is that it enables you to manage your Kubernetes applications alongside your other infrastructure, using the same configuration language and tooling. As we know, Helm allows us to create parameterized templates using Kubernetes’ declarative YAML manifests and a templating language but we still need to use bash scripts to execute the `helm` commands and pass in parameters to the Helm Chart. Some Helm Charts can have very complicated configurations with dozens of parameters. So, using Terraform eliminates the additional integration with external bash scripts that execute `helm` commands. 

At the same time, it also allows Kubernetes practitioners to develop Kubernetes templates in their native toolset. So if you have Kubernetes specialists in your organization that want to build their own custom Helm Charts, this allows them to keep doing their thing while plugging into a declarative deployment approach using Terraform. This also allows you to leverage the massive ecosystem that already exists for Helm and Kubernetes without any additional translation into HashiCorp Configuration Language (HCL).

Like the `kubernetes` provider, you need to initialize the provider first by declaring it as a required provider:

	terraform {
	    required_providers {
	        helm = {
	            source = "hashicorp/helm"
	            version = "~> 2.0.0"
	        }
	    }
	}

Then, in your root module, you need to create an instance of the provider. The provider configuration for the `helm` provider closely resembles that of the `kubernetes` provider. 

	provider "helm" {
	    kubernetes {
	        config_path = "~/.kube/config"
	    }
	}

In fact, both the `helm` and `kubernetes` providers can be used side-by-side in the same Terraform Module in case there are some additional Kubernetes resources that need to be provisioned to augment what’s in the Helm Chart itself.

The `helm` provider can be used to create a two-stage Terraform CI / CD pipeline where the first stage provisions the Cloud Environment using Terraform and the corresponding Cloud platform’s provider. The second stage uses the cluster connection and authentication settings output by the first stage to configure the `helm` provider and runs `terraform apply` again using a different Terraform codebase containing the Helm configuration.

![Helm Chart Anatomy][image-1]
_Terraform and Helm integration in a CI / CD pipeline_

The Terraform codebase for the second stage is often quite small, only using a single resource. The `helm_release` resource is the only resource in the provider—which is quite different if you have ever used one of the cloud platform providers like AWS, Azure or Google Cloud!

The `helm_release` resource simply takes the inputs that we would expect to pass to the `helm install` command by specifying the Chart name and version and an external repository (if necessary).

	resource "helm_release" "my_application" {
	    name       = "my-application"
	    repository = "https://kubernetes-charts.storage.googleapis.com/"
	    chart      = "my-application-chart"
	    version    = "1.0.0"
	}




[image-1]:	../images/Terraform-Terraform-Helm-CICD.png